# Day 4: 28 July 2023, Cambridge, UK

## Introduction

### 3D Data - Structure from Motion 

**Instructor**: Neil Jakeman

Structure from motion is an imaging technique for creating 3D images from 2D images. In this workshop we will cover 
how to image a variety of artefacts for humanities and collections research. We will look at strategies for different 
scenarios (e.g. [room scale capture](https://skfb.ly/oF9N6), [landscape capture](https://skfb.ly/o8ErV), and capturing 
[individual smaller items](https://skfb.ly/6SR8u) with differing textural qualities). We will consider how to 
systematically record the creation process for reproducibility and third-party critique. To explore the method we will 
use trial versions of Agisoft Metashape (30-day evaluation licence), which will allow us to see the technique in action.

**Pre-workshop preparations**: 

**Important** - You must install Agisoft Metashape (Standard) before the workshop begins, but do not install the trial software more than 
30 days in advance of the workshop; your license will expire.
The software we will be using is available at [https://www.agisoft.com/downloads/installer/](https://www.agisoft.com/downloads/installer/)
and is available for Mac, Windows and Linux. Note that both Standard and Professional editions of Metashape allow to run
the fully functional trial from the Activate Product dialog without requesting a trial key (the option Start a free 30-day 
trial should be selected in the Activation dialog).

You might like to attempt scanning a personal item in 3D? If so, consider bringing an item which doesn't have a reflective surface
and exhibits enough surface texture for the software to identify distinct regions. Photogrammetry doesn't work as well
on reflective and metallic surfaces, or with transparent objects.

We've included two sample datasets for those who haven't got cameras or objects to scan:
- [Bird Bath photoset ~70Mb](bird_bath.zip)
- [St.Peter minimal photoset ~1.7Mb](st_peter.zip)

It is perfectly possible to use photos taken with a phone to generate models, however you will find a more flexible option is to use
a camera that can be easily configured for different exposure settings, such as a DLSR or mirrorless. Also, make sure you have
the cables required to transfer images onto your computer.

### Teaching Computational Methods to Humanities Researchers

**Instructors**: Lucia Michielin, Jessica Witte

Teaching computational methods to researchers from non-STEM backgrounds, such as those working in humanities disciplines 
that have not historically incorporated digital methods, presents unique challenges. During this workshop, we are going 
to explore several pedagogical methods for training humanities researchers on digital research techniques. We will 
discuss and demo different training modalities, including hands-on live coding workshops, how-to guides to approach 
methods, and asynchronous online options. We will also explore ideas for good practice in supporting humanities 
researchers in incorporating computational techniques into their existing research. We will do this by exploring 
different training activities focusing on the same technique to see how to set learning environments to better engage 
with various audiences, and how to bridge the gap between computer science and humanities methodologies. The workshop 
will focus on text analysis techniques and will use Python. 

**Pre-workshop preparations**: 
Please familiarise yourself with the contents of [this document](https://github.com/DCS-training/TeachingDH/blob/main/AttendeesInstructions.md).

All of the material will be accessed through Google Colab, so you will not need to complete any installations on your machine.


**Instructions:**

We will simulate three learning experiences using roleplay. The formats are as follows:

1. **Standard workshop**: an instructor-led live coding tutorial in an introduction to the NLTK package in Python
2. **Digital Method of the Month**: an open discussion about text mining as a method, including what it takes to get started, potential use cases, and resources for learning
3. **Silent Disco**: an opportunity to receive real-time chat support while working through a written tutorial

You will be able to act as both an instructor/helper and an attendee. The various instructor roles will require different levels of engagement required. Therefore, if you do not feel comfortable speaking in front of a group, you might prefer to select a helper role or to volunteer as an instructor for one of the non-traditional workshop formats.

We have created four attendee profiles that reflect the backgrounds and experience levels of learners who enrol in our training workshops. Before we begin, you will receive an attendee profile that will inform your experience in each learning experience. Do your best to participate according to your assigned profile.

## Schedule

- 10.00 3D Data - Structure from Motion 1
- 11.30 Break
- 11.45 3D Data - Structure from Motion 2
- 13.00 Lunch
- 14.00 Teaching Computational Methods to Humanities Researchers 1
- 15.30 Break 
- 15.45 Teaching Computational Methods to Humanities Researchers 2
- 17.00 End

## Instructors

- [Neil Jakeman](https://kdl.kcl.ac.uk/who-we-are/neil-jakeman/), King's Digital Lab
- [Lucia Michielin](https://www.ed.ac.uk/profile/dr-lucia-michielin), Centre for Data, Culture & Society
- [Jessica Witte](https://www.research.ed.ac.uk/en/persons/jessica-witte), Centre for Data, Culture & Society
